{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:10:27.142591Z",
     "start_time": "2024-05-22T13:10:26.338204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %matplotlib qt6\n",
    "\n",
    "\n",
    "from mavlink.mavlink import MAVLinkController, DataAcquisitionThread\n",
    "from mavlink.mavlink.processor import GimbalProcessor, GlobalPositionProcessor, AttitudeProcessor\n",
    "\n",
    "\n",
    "mavlink_connection = MAVLinkController(\"udp:0.0.0.0:14550\")\n",
    "\n",
    "attitude_processor = AttitudeProcessor()\n",
    "global_position_processor = GlobalPositionProcessor()\n",
    "gimbal_processor = GimbalProcessor()\n",
    "\n",
    "acquisition_thread = DataAcquisitionThread(\n",
    "    mavlink_connection, \n",
    "    [\n",
    "        attitude_processor,\n",
    "        global_position_processor,\n",
    "        gimbal_processor\n",
    "    ]\n",
    ")\n",
    "acquisition_thread.start()"
   ],
   "id": "f20eed91790a313f",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:10:28.025049Z",
     "start_time": "2024-05-22T13:10:27.919975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data_stream import StreamReceiver\n",
    "from simulation.webots.controllers.ardupilot_vehicle_controller.drone_data import DroneData\n",
    "\n",
    "\n",
    "\n",
    "host = \"192.168.0.107\"\n",
    "port = 5588\n",
    "stream_receiver = StreamReceiver(host, port)"
   ],
   "id": "5b426c8077a3b88e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:29:01.820513Z",
     "start_time": "2024-05-22T15:29:01.814827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "latest_data = gimbal_processor.get_data()\n",
    "if latest_data:\n",
    "    print(\"GIMBAL\", [math.degrees(axis) for axis in latest_data.quaternion.to_euler()])\n"
   ],
   "id": "c6b11fe2653cf1f2",
   "execution_count": 62,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:29:34.573580Z",
     "start_time": "2024-05-22T15:29:34.569627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mavlink_connection.gimbal.set_angles(\n",
    "    roll=0,\n",
    "    pitch=-45,\n",
    "    yaw=-35\n",
    ")"
   ],
   "id": "91b02f52c7f03566",
   "execution_count": 67,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:29:36.167098Z",
     "start_time": "2024-05-22T15:29:35.734541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "data = stream_receiver.get_data()\n",
    "drone_data = DroneData.from_json(data)\n",
    "camera_frame = drone_data.camera.frame\n",
    "\n",
    "plt.imshow(camera_frame)"
   ],
   "id": "1126261d30d542b0",
   "execution_count": 68,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:30:05.899517Z",
     "start_time": "2024-05-22T15:30:04.787165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import random\n",
    "from deep_sort.deep_sort.tracker import Tracker\n",
    "from deep_sort.deep_sort.deep.extractor import Extractor\n",
    "from deep_sort.deep_sort.deep.configuration import ResNetConfiguration\n",
    "from deep_sort.deep_sort.deep.weights import RESNET18_WEIGHTS\n",
    "\n",
    "\n",
    "model = YOLO(\"yolov8n-visdrone.pt\")\n",
    "\n",
    "detection_threshold = 0.3\n",
    "\n",
    "resnet = ResNetConfiguration(\n",
    "    base=\"resnet18\",\n",
    "    weights_path=RESNET18_WEIGHTS,\n",
    "    use_cuda=False\n",
    ")\n",
    "extractor = Extractor(model=resnet, batch_size=4)\n",
    "\n",
    "tracker = Tracker(\n",
    "    feature_extractor=extractor,\n",
    "    max_iou_distance=0.7,\n",
    "    max_cosine_distance=0.7\n",
    ")\n",
    "\n",
    "colors = [(\n",
    "    random.randint(0, 255),\n",
    "    random.randint(0, 255),\n",
    "    random.randint(0, 255)) for j in range(10)\n",
    "]"
   ],
   "id": "685840f6732bc133",
   "execution_count": 69,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:30:05.930034Z",
     "start_time": "2024-05-22T15:30:05.901519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geospatial as geo_utils\n",
    "\n",
    "\n",
    "file_path = \"S36E149.hgt\"\n",
    "geospatial = geo_utils.GEOSpatial(file_path)"
   ],
   "id": "af2a5291803a56fb",
   "execution_count": 70,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:30:14.322826Z",
     "start_time": "2024-05-22T15:30:06.661752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "for i in range(10):\n",
    "    data = stream_receiver.get_data()\n",
    "    drone_data = DroneData.from_json(data)\n",
    "    camera_frame = drone_data.camera.frame\n",
    "    \n",
    "    result = model.predict(\n",
    "        source=camera_frame,\n",
    "        imgsz=camera_frame.shape[:2],\n",
    "        classes=None,\n",
    "        conf=0.3,\n",
    "        iou=0.5,\n",
    "        max_det=10,\n",
    "        augment=False,\n",
    "        agnostic_nms=True,\n",
    "        device=\"cpu\",\n",
    "        half=False,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "    \n",
    "    detections = []\n",
    "    for result in result.boxes.data.tolist():    \n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "        x1 = int(x1)\n",
    "        x2 = int(x2)\n",
    "        y1 = int(y1)\n",
    "        y2 = int(y2)\n",
    "        class_id = int(class_id)    \n",
    "        \n",
    "        detections.append([x1, y1, x2, y2, score, class_id])\n",
    "        \n",
    "    tracker.update(camera_frame, detections)\n",
    "    \n",
    "for track in tracker.tracks:\n",
    "    x1, y1, x2, y2 = track.to_tlbr()\n",
    "    track_id = track.track_id\n",
    "    class_id = track.class_id\n",
    "\n",
    "    print(\n",
    "        x1, y1, x2, y2, track_id, class_id\n",
    "    )\n",
    "    \n",
    "    color = colors[track_id % len(colors)]\n",
    "\n",
    "    cv2.rectangle(\n",
    "        camera_frame,\n",
    "        (int(x1), int(y1)),\n",
    "        (int(x2), int(y2)),\n",
    "        color,\n",
    "        3\n",
    "    )\n",
    "\n",
    "    cx = int((x1 + x2) / 2)\n",
    "    cy = int((y1 + y2) / 2)\n",
    "\n",
    "    cv2.circle(\n",
    "        camera_frame,\n",
    "        (cx, cy),\n",
    "        3,\n",
    "        color,\n",
    "        -1\n",
    "    )\n",
    "\n",
    "    cv2.putText(\n",
    "        camera_frame,\n",
    "        f\"ID: {track_id}\",\n",
    "        (cx + 10, cy),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        (0, 0, 255),\n",
    "        2\n",
    "    )\n",
    "\n",
    "plt.imshow(camera_frame)"
   ],
   "id": "1765123ac6326c46",
   "execution_count": 71,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:30:14.366853Z",
     "start_time": "2024-05-22T15:30:14.324816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = stream_receiver.get_data()\n",
    "drone_data = DroneData.from_json(data)\n",
    "camera_frame = drone_data.camera.frame\n",
    "\n",
    "image_width = drone_data.camera.width\n",
    "image_height = drone_data.camera.height\n",
    "\n",
    "fov_horizontal = drone_data.camera.fov\n",
    "fov_vertical = 2 * math.atan(math.tan(fov_horizontal / 2) * (image_height / image_width))\n",
    "\n",
    "gimbal_roll, gimbal_pitch, gimbal_yaw = gimbal_processor.get_data().quaternion.to_euler()\n",
    "attitude = attitude_processor.get_data()\n",
    "\n",
    "drone_roll = math.radians(attitude.roll)\n",
    "drone_pitch = math.radians(attitude.pitch) \n",
    "\n",
    "global_position = global_position_processor.get_data()\n",
    "drone_heading = math.radians(global_position.heading)\n",
    "\n",
    "view_roll = gimbal_roll + drone_roll\n",
    "view_pitch = gimbal_pitch + drone_pitch\n",
    "view_yaw = gimbal_yaw + drone_heading"
   ],
   "id": "8032500d6aac1193",
   "execution_count": 72,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:32:39.050408Z",
     "start_time": "2024-05-22T15:32:38.919440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = stream_receiver.get_data()\n",
    "drone_data = DroneData.from_json(data)\n",
    "camera_frame = drone_data.camera.frame\n",
    "\n",
    "cv2.imwrite(\"before.png\", camera_frame)\n",
    "plt.imshow(camera_frame)"
   ],
   "id": "89b594e2c7882f0e",
   "execution_count": 73,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:33:04.720527Z",
     "start_time": "2024-05-22T15:33:04.696803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for track in tracker.tracks:\n",
    "    x1, y1, x2, y2 = track.to_tlbr()\n",
    "    track_id = track.track_id\n",
    "    class_id = track.class_id\n",
    "    \n",
    "    if model.names[class_id] == \"car\":\n",
    "        detection_offset = geo_utils.detection_angles(geo_utils.find_center(x1, y1, x2, y2), (image_width, image_height), fov_horizontal, fov_vertical)\n",
    "        \n",
    "        direction_vector = geo_utils.calculate_direction_vector((view_roll, view_pitch, view_yaw), detection_offset)\n",
    "    \n",
    "        target_location = geo_utils.find_target_location(global_position, direction_vector, geospatial)\n",
    "        \n",
    "        print(target_location)\n",
    "    "
   ],
   "id": "4baa4a55d50328a8",
   "execution_count": 74,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:33:08.986767Z",
     "start_time": "2024-05-22T15:33:08.980423Z"
    }
   },
   "cell_type": "code",
   "source": "mavlink_connection.gimbal.set_roi_location(*target_location)",
   "id": "3a30ab76ca2176b7",
   "execution_count": 75,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:37:25.986518Z",
     "start_time": "2024-05-22T15:37:25.601811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = stream_receiver.get_data()\n",
    "drone_data = DroneData.from_json(data)\n",
    "camera_frame = drone_data.camera.frame\n",
    "\n",
    "cv2.imwrite(\"after.png\", camera_frame)\n",
    "plt.imshow(camera_frame)"
   ],
   "id": "4b8e794adc1ed251",
   "execution_count": 79,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T20:59:03.644466Z",
     "start_time": "2024-05-21T20:58:40.947632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(100):\n",
    "    data = stream_receiver.get_data()\n",
    "    drone_data = DroneData.from_json(data)\n",
    "    camera_frame = drone_data.camera.frame\n",
    "    \n",
    "    result = model.predict(\n",
    "        source=camera_frame,\n",
    "        imgsz=camera_frame.shape[:2],\n",
    "        classes=None,\n",
    "        conf=0.3,\n",
    "        iou=0.5,\n",
    "        max_det=10,\n",
    "        augment=False,\n",
    "        agnostic_nms=True,\n",
    "        device=\"cpu\",\n",
    "        half=False,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "    \n",
    "    detections = []\n",
    "    for result in result.boxes.data.tolist():    \n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "        x1 = int(x1)\n",
    "        x2 = int(x2)\n",
    "        y1 = int(y1)\n",
    "        y2 = int(y2)\n",
    "        class_id = int(class_id)    \n",
    "        \n",
    "        detections.append([x1, y1, x2, y2, score, class_id])\n",
    "        \n",
    "    tracker.update(camera_frame, detections)\n",
    "        \n",
    "    image_width = drone_data.camera.width\n",
    "    image_height = drone_data.camera.height\n",
    "    \n",
    "    fov_horizontal = drone_data.camera.fov\n",
    "    fov_vertical = 2 * math.atan(math.tan(fov_horizontal / 2) * (image_height / image_width))\n",
    "    \n",
    "    gimbal_roll, gimbal_pitch, gimbal_yaw = gimbal_processor.get_data().quaternion.to_euler()\n",
    "    attitude = attitude_processor.get_data()\n",
    "    \n",
    "    drone_roll = math.radians(attitude.roll)\n",
    "    drone_pitch = math.radians(attitude.pitch) \n",
    "    \n",
    "    global_position = global_position_processor.get_data()\n",
    "    drone_heading = math.radians(global_position.heading)\n",
    "    \n",
    "    view_roll = gimbal_roll + drone_roll\n",
    "    view_pitch = gimbal_pitch + drone_pitch\n",
    "    view_yaw = gimbal_yaw + drone_heading\n",
    "    \n",
    "    for track in tracker.tracks:\n",
    "        x1, y1, x2, y2 = track.to_tlbr()\n",
    "        track_id = track.track_id\n",
    "        class_id = track.class_id\n",
    "        \n",
    "        detection_offset = geo_utils.detection_angles(geo_utils.find_center(x1, y1, x2, y2), (image_width, image_height), fov_horizontal, fov_vertical)\n",
    "        \n",
    "        direction_vector = geo_utils.calculate_direction_vector((view_roll, view_pitch, view_yaw), detection_offset)\n",
    "    \n",
    "        target_location = geo_utils.find_target_location(global_position, direction_vector, geospatial)            \n",
    "        \n",
    "        print(track_id, target_location)"
   ],
   "id": "586a60023009e616",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:41:25.998877Z",
     "start_time": "2024-05-22T14:41:01.897303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data_dictionary = {}\n",
    "\n",
    "fps = 30\n",
    "total_frames = 15 * fps\n",
    "\n",
    "progress_bar = tqdm(total=total_frames)\n",
    "\n",
    "for frame_number in range(total_frames):\n",
    "    gimbal_roll, gimbal_pitch, gimbal_yaw = gimbal_processor.get_data().quaternion.to_euler()\n",
    "    attitude = attitude_processor.get_data()\n",
    "    drone_roll = math.radians(attitude.roll)\n",
    "    drone_pitch = math.radians(attitude.pitch)\n",
    "    global_position = global_position_processor.get_data()\n",
    "    drone_heading = math.radians(global_position.heading)\n",
    "    view_roll = gimbal_roll + drone_roll\n",
    "    view_pitch = gimbal_pitch + drone_pitch\n",
    "    view_yaw = gimbal_yaw + drone_heading\n",
    "    \n",
    "    data = stream_receiver.get_data()\n",
    "    drone_data = DroneData.from_json(data)\n",
    "    \n",
    "    data_dictionary[frame_number] = {\n",
    "        \"view_roll\": view_roll,\n",
    "        \"view_pitch\": view_pitch,\n",
    "        \"view_yaw\": view_yaw,\n",
    "        \"global_position\": global_position,\n",
    "        \"camera\": drone_data.camera\n",
    "    }\n",
    "    \n",
    "    progress_bar.update(1)"
   ],
   "id": "aa9bdd2aadac22a3",
   "execution_count": 49,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:44:16.401117Z",
     "start_time": "2024-05-22T14:41:59.929027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "progress_bar = tqdm(total=total_frames)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  \n",
    "out = cv2.VideoWriter(\"demo_video.mp4\", fourcc, 30, (640, 480))\n",
    "\n",
    "tracker = Tracker(\n",
    "    feature_extractor=extractor,\n",
    "    max_iou_distance=0.7,\n",
    "    max_cosine_distance=0.7\n",
    ")\n",
    "\n",
    "for frame_number in range(total_frames):\n",
    "    frame_data = data_dictionary[frame_number]\n",
    "\n",
    "    camera = frame_data[\"camera\"]\n",
    "    \n",
    "    result = model.predict(\n",
    "        source=camera.frame,\n",
    "        imgsz=camera.frame.shape[:2],\n",
    "        classes=None,\n",
    "        conf=0.3,\n",
    "        iou=0.5,\n",
    "        max_det=10,\n",
    "        augment=False,\n",
    "        agnostic_nms=True,\n",
    "        device=\"cpu\",\n",
    "        half=False,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "    \n",
    "    detections = []\n",
    "    for result in result.boxes.data.tolist():    \n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "        x1 = int(x1)\n",
    "        x2 = int(x2)\n",
    "        y1 = int(y1)\n",
    "        y2 = int(y2)\n",
    "        class_id = int(class_id)    \n",
    "        \n",
    "        detections.append([x1, y1, x2, y2, score, class_id])\n",
    "        \n",
    "    tracker.update(camera_frame, detections)\n",
    "    \n",
    "    view_roll = frame_data[\"view_roll\"]\n",
    "    view_pitch = frame_data[\"view_pitch\"]\n",
    "    view_yaw = frame_data[\"view_yaw\"]\n",
    "    \n",
    "    global_position = frame_data[\"global_position\"]\n",
    "    \n",
    "    camera_frame = camera.frame.copy()\n",
    "    for track in tracker.tracks:\n",
    "        x1, y1, x2, y2 = track.to_tlbr()\n",
    "        track_id = track.track_id\n",
    "        class_id = track.class_id\n",
    "        \n",
    "        detection_offset = geo_utils.detection_angles(geo_utils.find_center(x1, y1, x2, y2), (image_width, image_height), fov_horizontal, fov_vertical)\n",
    "        \n",
    "        direction_vector = geo_utils.calculate_direction_vector((view_roll, view_pitch, view_yaw), detection_offset)\n",
    "    \n",
    "        target_location = geo_utils.find_target_location(global_position, direction_vector, geospatial)            \n",
    "        \n",
    "        color = colors[track_id % len(colors)]\n",
    "\n",
    "        cv2.rectangle(\n",
    "            camera_frame,\n",
    "            (int(x1), int(y1)),\n",
    "            (int(x2), int(y2)),\n",
    "            color,\n",
    "            2\n",
    "        )\n",
    "    \n",
    "        cx = int((x1 + x2) / 2)\n",
    "        cy = int((y1 + y2) / 2)\n",
    "    \n",
    "        cv2.circle(\n",
    "            camera_frame,\n",
    "            (cx, cy),\n",
    "            3,\n",
    "            color,\n",
    "            -1\n",
    "        )\n",
    "    \n",
    "        cv2.putText(\n",
    "            camera_frame,\n",
    "            f\"ID: {track_id}\",\n",
    "            (cx + 10, cy),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 255),\n",
    "            1\n",
    "        )\n",
    "        \n",
    "        distance = geo_utils.distance_between_locations(\n",
    "            global_position.latitude, \n",
    "            global_position.longitude, \n",
    "            global_position.altitude, \n",
    "            *target_location)\n",
    "        \n",
    "        cv2.putText(\n",
    "            camera_frame,\n",
    "            f\"LAT: {round(target_location[0], 5)}\",\n",
    "            (cx + 10, cy + 15),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 255),\n",
    "            1\n",
    "        )\n",
    "        cv2.putText(\n",
    "            camera_frame,\n",
    "            f\"LON: {round(target_location[1], 5)}\",\n",
    "            (cx + 10, cy + 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 255),\n",
    "            1\n",
    "        )\n",
    "        cv2.putText(\n",
    "            camera_frame,\n",
    "            f\"RANGE: {round(distance, 1)}\",\n",
    "            (cx + 10, cy + 45),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 255),\n",
    "            1\n",
    "        )\n",
    "    \n",
    "    out.write(camera_frame)\n",
    "    progress_bar.update(1)\n",
    "    \n",
    "out.release()\n",
    "\n",
    "plt.imshow(camera_frame)"
   ],
   "id": "ac56eba16a363680",
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from ballistics import projectile\n",
    "\n",
    "# Пример использования\n",
    "g = 9.81  # ускорение свободного падения\n",
    "c = 0.3  # коэффициент сопротивления среды\n",
    "dt = 0.01  # шаг времени\n",
    "v0 = 0.1  # начальная скорость\n",
    "theta = 120  # угол в градусах (вертикальный угол)\n",
    "phi = 13  # угол в градусах (горизонтальный угол)\n",
    "ro = 1.225  # плотность среды\n",
    "area = 0.1  # площадь поперечного сечения объекта\n",
    "mass = 1  # масса объекта\n",
    "tr = True  # учет сопротивления среды\n",
    "h0 = 30  # начальная высота\n",
    "wind_speed = 3\n",
    "wind_angle = 37\n",
    "\n",
    "x, y, z, t = projectile(v0, h0, theta, phi, tr, ro, c, area, mass, wind_speed, wind_angle, dt)\n",
    "\n",
    "print(\"Траектория:\")\n",
    "for i in range(len(x)):\n",
    "    print(f\"t = {i * dt} сек: x = {x[i]} м, y = {y[i]} м, z = {z[i]} м\")\n",
    "print(f\"Время полета: {t} сек\")"
   ],
   "id": "44c3017736060444",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot(x, y, z, label=\"Траєкторія\", c='c')\n",
    "\n",
    "ax.scatter(x[0], y[0], z[0], label=\"Дрон\", c='b', marker='o', s=100)\n",
    "ax.scatter(x[-1], y[-1], z[-1], label=\"Ціль\", c='r', marker='*', s=300)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "offset = 10\n",
    "x_max, x_min = max(x) + offset, min(x) - offset\n",
    "y_max, y_min = max(y) + offset, min(y) - offset\n",
    "\n",
    "ground_x = numpy.linspace(x_min, x_max, 1000)\n",
    "ground_y = numpy.linspace(y_min, y_max, 1000)\n",
    "ground_x, ground_y = numpy.meshgrid(ground_x, ground_y)\n",
    "ground_z = numpy.zeros_like(ground_x)\n",
    "ax.plot_surface(ground_x, ground_y, ground_z, color='green', alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "150c55f152f5b9fa",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
